{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gigachain faiss-cpu sentence-transformers sentencepiece rank_bm25 datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from langchain.docstore.base import Document\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим Question Answering датасет на русском языке - [SberQuAD](https://huggingface.co/datasets/sberquad).\n",
    "\n",
    "Каждая запись содержит несколько полей, из которых нам нужны будут только 2:\n",
    "- **question** - неструктурированный запрос или обычный вопрос;\n",
    "- **contex** - релевантный этому вопросу параграф из базы знаний (пассаж)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6aebc9caff49f0a80ed9d76fb57a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9e4184ba99448ab85c80523cdadb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8817b3d0b2e940229311e05761b58784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3043a41473e34187844b8d1aca76655d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104903180b964fdf95c01bc023787f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.93M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c041d2561d4d49a694ee1075d92da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41c2d1700ba4143b8860697443402e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eacaed0f0374cf886cf672d5a92c919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/45328 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819415dc1a7447869bbc885628371fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10f3e88d8784322a0f2a3906d0fd0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/23936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 62310,\n",
       " 'title': 'SberChallenge',\n",
       " 'context': 'В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.',\n",
       " 'question': 'чем представлены органические остатки?',\n",
       " 'answers': {'text': ['известковыми выделениями сине-зелёных водорослей'],\n",
       "  'answer_start': [109]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"sberquad\")\n",
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = ds[\"validation\"]\n",
    "documents = [\n",
    "    Document(page_content=context) for context in set(validation_ds[\"context\"])\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ретривал"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача - среди всех возможных пассажей найти наиболее подходящий вопросу, чтобы на основе него ГигаЧат смог дать максимально точный ответ.\n",
    "\n",
    "Для этой задачи существует множество обёрток различных retrieval подходов внутри пакета `langchain.retrievers`. Попробуем найти наиболее точный для наших данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинг модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать нейросетевой ретривер (эмбеддер) с векторной базой данных.\n",
    "\n",
    "В качестве эмбеддингов возьмём специализированную мультиязычную модель [intfloat/multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base). Модель требует использовать различные префиксы для запросов и пассажей, поэтому создадим свой класс `HuggingFaceE5Embeddings` под эту логику, немного переопределив стандартный класс `langchain.embeddings.HuggingFaceEmbeddings`.\n",
    "\n",
    "Вы можете попробовать использовать любую энкодер модель для вашей задачи. Для русского языка существует открытый бенчмарк энкодеров предложений [avidale/encodechka](https://github.com/avidale/encodechka#лидерборд), который содержит отдельный лидерборд для ранжирования. Также можете посмотреть специализированный мультиязычный лидерборд [MTEB](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Coroutine, Any\n",
    "\n",
    "\n",
    "class HuggingFaceE5Embeddings(HuggingFaceEmbeddings):\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        text = f\"query: {text}\"\n",
    "        return super().embed_query(text)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        texts = [f\"passage: {text}\" for text in texts]\n",
    "        return super().embed_documents(texts)\n",
    "\n",
    "    async def aembed_query(self, text: str) -> Coroutine[Any, Any, List[float]]:\n",
    "        text = f\"query: {text}\"\n",
    "        return await super().aembed_query(text)\n",
    "\n",
    "    async def aembed_documents(\n",
    "        self, texts: List[str]\n",
    "    ) -> Coroutine[Any, Any, List[List[float]]]:\n",
    "        texts = [f\"passage: {text}\" for text in texts]\n",
    "        return await super().aembed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778b64a4ab6d4680b1a9d6de58e6f0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d323bf24dd4ad28fb21f0bf3982037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17146a5accd94950930a0143fc8374cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/179k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4cdc6a84fe4de280494607afc513a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c38a1f6ad16424ea567df0423148970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d9c0b86e7b46a7b9414bd86b5831a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/config.json:   0%|          | 0.00/686 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2496d6f0154844aa9e21f46be77c0142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\work\\hacks\\gigachat\\ai-onboarding\\ai\\retrieve.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m embedding \u001b[39m=\u001b[39m HuggingFaceE5Embeddings(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mintfloat/multilingual-e5-base\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\langchain\\embeddings\\huggingface.py:65\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     61\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import sentence_transformers python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m sentence_transformers\u001b[39m.\u001b[39mSentenceTransformer(\n\u001b[0;32m     66\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name, cache_folder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     83\u001b[0m     model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m     86\u001b[0m         \u001b[39m# Download from hub with caching\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[39m=\u001b[39;49mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msentence-transformers\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[39m=\u001b[39;49m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mflax_model.msgpack\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrust_model.ot\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtf_model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):    \u001b[39m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_sbert_model(model_path)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\sentence_transformers\\util.py:491\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(huggingface_hub\u001b[39m.\u001b[39m__version__) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m0.8.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    487\u001b[0m     \u001b[39m# huggingface_hub v0.8.1 introduces a new cache layout. We sill use a manual layout\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     \u001b[39m# And need to pass legacy_cache_layout=True to avoid that a warning will be printed\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     cached_download_args[\u001b[39m'\u001b[39m\u001b[39mlegacy_cache_layout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m path \u001b[39m=\u001b[39m cached_download(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcached_download_args)\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.lock\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    494\u001b[0m     os\u001b[39m.\u001b[39mremove(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.lock\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\huggingface_hub\\file_download.py:821\u001b[0m, in \u001b[0;36mcached_download\u001b[1;34m(url, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[0;32m    819\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[1;32m--> 821\u001b[0m     http_get(\n\u001b[0;32m    822\u001b[0m         url_to_download,\n\u001b[0;32m    823\u001b[0m         temp_file,\n\u001b[0;32m    824\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    825\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m    826\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    827\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m    828\u001b[0m     )\n\u001b[0;32m    830\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, cache_path)\n\u001b[0;32m    831\u001b[0m _chmod_and_replace(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\huggingface_hub\\file_download.py:544\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    543\u001b[0m     progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n\u001b[1;32m--> 544\u001b[0m     temp_file\u001b[39m.\u001b[39;49mwrite(chunk)\n\u001b[0;32m    545\u001b[0m     new_resume_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[0;32m    546\u001b[0m     \u001b[39m# Some data has been downloaded from the server so we reset the number of retries.\u001b[39;00m\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\tempfile.py:483\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39m@_functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    482\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 483\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "embedding = HuggingFaceE5Embeddings(model_name=\"intfloat/multilingual-e5-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А в качестве векторной базы данных используем [faiss](https://faiss.ai/), как самое популярное и простое решение для подобных задач. При создании экземпляра векторной БД для каждого документа считается его векторное представление, поиск по которому и происходит при каждом запросе - вся база данных ранжируется по степени релевантности входному запросу. В результате `embedding_retriever` вернёт `k = 5` самых подходящих пассажей.\n",
    "\n",
    "GigaChain, как и Langchain, предоставляет большое количество интерфейсов под все самые популярные векторные БД, полный список можно найти на [странице документации](https://python.langchain.com/docs/integrations/vectorstores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_db = FAISS.from_documents(documents, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_retriever = faiss_db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5036/5036 [08:03<00:00, 10.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'embedding_retrieved'],\n",
       "    num_rows: 5036\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds = validation_ds.map(\n",
    "    lambda x: {\n",
    "        \"embedding_retrieved\": [\n",
    "            passage.page_content\n",
    "            for passage in embedding_retriever.get_relevant_documents(x[\"question\"])\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "validation_ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве целевой метрики используем точность нахождения целевого пассажа среди топ-5 отранжированных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_top(dataset: datasets.Dataset, right_column: str, answer_column: str) -> float:\n",
    "    temp_dataset = dataset.map(\n",
    "        lambda x: {\"is_right_retrieved\": x[right_column] in x[answer_column]}\n",
    "    )\n",
    "    return sum(temp_dataset[\"is_right_retrieved\"]) / len(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e74ed8fb584c248d8bb87fc5247ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'embedding_retrieved'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\work\\hacks\\gigachat\\ai-onboarding\\ai\\retrieve.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m acc_top(validation_ds, \u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39membedding_retrieved\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32md:\\work\\hacks\\gigachat\\ai-onboarding\\ai\\retrieve.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macc_top\u001b[39m(dataset: datasets\u001b[39m.\u001b[39mDataset, right_column: \u001b[39mstr\u001b[39m, answer_column: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     temp_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: {\u001b[39m\"\u001b[39;49m\u001b[39mis_right_retrieved\u001b[39;49m\u001b[39m\"\u001b[39;49m: x[right_column] \u001b[39min\u001b[39;49;00m x[answer_column]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(temp_dataset[\u001b[39m\"\u001b[39m\u001b[39mis_right_retrieved\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(temp_dataset)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\datasets\\arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3083\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   3084\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3085\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3086\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[0;32m   3087\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3088\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3089\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3090\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   3091\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\datasets\\arrow_dataset.py:3442\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3440\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3441\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3442\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[0;32m   3443\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[0;32m   3444\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\datasets\\arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3343\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3344\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3345\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39mfn_args, \u001b[39m*\u001b[39madditional_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3347\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3348\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3349\u001b[0m     }\n",
      "\u001b[1;32md:\\work\\hacks\\gigachat\\ai-onboarding\\ai\\retrieve.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macc_top\u001b[39m(dataset: datasets\u001b[39m.\u001b[39mDataset, right_column: \u001b[39mstr\u001b[39m, answer_column: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     temp_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m x: {\u001b[39m\"\u001b[39m\u001b[39mis_right_retrieved\u001b[39m\u001b[39m\"\u001b[39m: x[right_column] \u001b[39min\u001b[39;00m x[answer_column]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(temp_dataset[\u001b[39m\"\u001b[39m\u001b[39mis_right_retrieved\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(temp_dataset)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\datasets\\formatting\\formatting.py:270\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m--> 270\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[key]\n\u001b[0;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys_to_format:\n\u001b[0;32m    272\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'embedding_retrieved'"
     ]
    }
   ],
   "source": [
    "acc_top(validation_ds, \"context\", \"embedding_retrieved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x98 in position 459: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\work\\hacks\\gigachat\\ai-onboarding\\ai\\retrieve.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/hacks/gigachat/ai-onboarding/ai/retrieve.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m \u001b[39mimport\u001b[39;00m EnsembleRetriever\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\langchain\\retrievers\\__init__.py:60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mre_phraser\u001b[39;00m \u001b[39mimport\u001b[39;00m RePhraseQueryRetriever\n\u001b[0;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mremote_retriever\u001b[39;00m \u001b[39mimport\u001b[39;00m RemoteLangChainRetriever\n\u001b[1;32m---> 60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mself_query\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m SelfQueryRetriever\n\u001b[0;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVMRetriever\n\u001b[0;32m     62\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mretrievers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtavily_search_api\u001b[39;00m \u001b[39mimport\u001b[39;00m TavilySearchAPIRetriever\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\langchain\\retrievers\\self_query\\base.py:16\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorStore\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanager\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     AsyncCallbackManagerForRetrieverRun,\n\u001b[0;32m     14\u001b[0m     CallbackManagerForRetrieverRun,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquery_constructor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m load_query_constructor_runnable\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquery_constructor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mir\u001b[39;00m \u001b[39mimport\u001b[39;00m StructuredQuery, Visitor\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquery_constructor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschema\u001b[39;00m \u001b[39mimport\u001b[39;00m AttributeInfo\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\langchain\\chains\\__init__.py:50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm_math\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m LLMMathChain\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm_requests\u001b[39;00m \u001b[39mimport\u001b[39;00m LLMRequestsChain\n\u001b[1;32m---> 50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm_summarization_checker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m LLMSummarizationCheckerChain\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloading\u001b[39;00m \u001b[39mimport\u001b[39;00m load_chain\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmapreduce\u001b[39;00m \u001b[39mimport\u001b[39;00m MapReduceChain\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\langchain\\chains\\llm_summarization_checker\\base.py:26\u001b[0m\n\u001b[0;32m     20\u001b[0m CREATE_ASSERTIONS_PROMPT \u001b[39m=\u001b[39m PromptTemplate\u001b[39m.\u001b[39mfrom_file(\n\u001b[0;32m     21\u001b[0m     PROMPTS_DIR \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcreate_facts.txt\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m CHECK_ASSERTIONS_PROMPT \u001b[39m=\u001b[39m PromptTemplate\u001b[39m.\u001b[39mfrom_file(\n\u001b[0;32m     24\u001b[0m     PROMPTS_DIR \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcheck_facts.txt\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39massertions\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m REVISED_SUMMARY_PROMPT \u001b[39m=\u001b[39m PromptTemplate\u001b[39m.\u001b[39;49mfrom_file(\n\u001b[0;32m     27\u001b[0m     PROMPTS_DIR \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mrevise_summary.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, [\u001b[39m\"\u001b[39;49m\u001b[39mchecked_assertions\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m ARE_ALL_TRUE_PROMPT \u001b[39m=\u001b[39m PromptTemplate\u001b[39m.\u001b[39mfrom_file(\n\u001b[0;32m     30\u001b[0m     PROMPTS_DIR \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mare_all_true_prompt.txt\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mchecked_assertions\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_sequential_chain\u001b[39m(\n\u001b[0;32m     35\u001b[0m     llm: BaseLanguageModel,\n\u001b[0;32m     36\u001b[0m     create_assertions_prompt: PromptTemplate,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SequentialChain:\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\site-packages\\langchain_core\\prompts\\prompt.py:192\u001b[0m, in \u001b[0;36mPromptTemplate.from_file\u001b[1;34m(cls, template_file, input_variables, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a prompt from a file.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39m    The prompt loaded from the file.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mstr\u001b[39m(template_file), \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 192\u001b[0m     template \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(input_variables\u001b[39m=\u001b[39minput_variables, template\u001b[39m=\u001b[39mtemplate, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\PYTHONLANG\\Python10.6\\lib\\encodings\\cp1251.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_decode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x98 in position 459: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever, BM25Retriever"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем оценить качество другого ретривала - [BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)\n",
    "\n",
    "Попробуйте использовать токенизацию предложений на русском от библиотеки [natasha/razdel](https://github.com/natasha/razdel#usage), [aatimofeev/spacy_russian_tokenizer](https://github.com/aatimofeev/spacy_russian_tokenizer#usage) или [Koziev/rutokenizer](https://github.com/Koziev/rutokenizer#примеры) - они могут улучшить точность поиска на ваших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def tokenize(s: str) -> list[str]:\n",
    "    \"\"\"Очень простая функция разбития предложения на слова\"\"\"\n",
    "    return s.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=documents,\n",
    "    preprocess_func=tokenize,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5036/5036 [06:34<00:00, 12.75 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'embedding_retrieved', 'bm25_retrieved'],\n",
       "    num_rows: 5036\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds = validation_ds.map(\n",
    "    lambda x: {\n",
    "        \"bm25_retrieved\": [\n",
    "            passage.page_content\n",
    "            for passage in bm25_retriever.get_relevant_documents(x[\"question\"])\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5036/5036 [00:01<00:00, 3617.90 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9197776012708498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_top(validation_ds, \"context\", \"bm25_retrieved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ансамбль"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь попробуем увеличить точность поиска, объединив работу двух предыдущих ретривалов алгоритмом [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf). Для него есть удобная обёртка `langchain.retrievers.EnsembleRetriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_retriever = faiss_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=documents,\n",
    "    preprocess_func=tokenize,\n",
    "    k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[embedding_retriever, bm25_retriever],\n",
    "    weights=[0.4, 0.6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5036/5036 [20:28<00:00,  4.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'embedding_retrieved', 'bm25_retrieved', 'retrieved'],\n",
       "    num_rows: 5036\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds = validation_ds.map(\n",
    "    lambda x: {\n",
    "        \"retrieved\": [\n",
    "            passage.page_content\n",
    "            for passage in ensemble_retriever.get_relevant_documents(x[\"question\"])\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5036/5036 [00:01<00:00, 3121.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9690230341540905"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_top(validation_ds, \"context\", \"retrieved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E2E решение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На улучшенном решении уже можно строить вопросно-ответную систему с достаточно хорошей точностью ответов. Ограничимся простой цепочкой `langchain.chains.RetrievalQA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.gigachat import GigaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GigaChat(credentials=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Что такое вода?',\n",
       " 'result': 'Вода — это бинарное неорганическое соединение, состоящее из двух атомов водорода и одного атома кислорода, соединенных ковалентной связью. Она является прозрачной жидкостью без цвета, запаха и вкуса при нормальных условиях. Вода может существовать в различных состояниях, включая жидкое, твердое и газообразное. Она играет важную роль в жизни на Земле и является основой для существования всех живых организмов.',\n",
       " 'source_documents': [Document(page_content='На самом деле из-за низкого давления вода не может существовать в жидком состоянии на большей части (около 70 %) поверхности Марса. Вода в состоянии льда была обнаружена в марсианском грунте космическим аппаратом НАСА Феникс . В то же время собранные марсоходами Спирит и Opportunity геологические данные позволяют предположить, что в далёком прошлом вода покрывала значительную часть поверхности Марса. Наблюдения в течение последнего десятилетия позволили обнаружить в некоторых местах на поверхности Марса слабую гейзерную активность. По наблюдениям с космического аппарата Mars Global Surveyor , некоторые части южной полярной шапки Марса постепенно отступают.'),\n",
       "  Document(page_content='Оптические свойства воды оцениваются по её прозрачности, которая в свою очередь зависит от длины волны излучения, проходящего через воду. Вследствие поглощения оранжевых и красных компонентов света вода приобретает голубоватую окраску. Вода прозрачна только для видимого света и сильно поглощает инфракрасное излучение, поэтому на инфракрасных фотографиях водная поверхность всегда получается чёрной. Ультрафиолетовые лучи легко проходят через воду, поэтому растительные организмы способны развиваться в толще воды и на дне водоёмов, инфракрасные лучи проникают только в поверхностный слой. Вода отражает 5 % солнечных лучей, в то время как снег — около 85 %. Под лёд океана проникает только 2 % солнечного света.'),\n",
       "  Document(page_content='Концентрация инертных газов, аргона, криптона и ксенона, превышает их количество на Солнце (см. таблицу), а концентрация неона явно меньше. Присутствует незначительное количество простых углеводородов: этана, ацетилена и диацетилена, — которые формируются под воздействием солнечной ультрафиолетовой радиации и заряженных частиц, прибывающих из магнитосферы Юпитера. Диоксид углерода, моноксид углерода и вода в верхней части атмосферы, как полагают, своим присутствием обязаны столкновениям с атмосферой Юпитера комет, таких, например, как комета Шумейкеров-Леви 9. Вода не может прибывать из тропосферы, потому что тропопауза, действующая как холодная ловушка, эффективно препятствует поднятию воды до уровня стратосферы.'),\n",
       "  Document(page_content='Вода́ (оксид водорода) — бинарное неорганическое соединение с химической формулой Н2O. Молекула воды состоит из двух атомов водорода и одного — кислорода, которые соединены между собой ковалентной связью. При нормальных условиях представляет собой прозрачную жидкость, не имеющую цвета (при малой толщине слоя), запаха и вкуса. В твёрдом состоянии называется льдом (кристаллы льда могут образовывать снег или иней), а в газообразном — водяным паром. Вода также может существовать в виде жидких кристаллов (на гидрофильных поверхностях). Составляет приблизительно около 0,05 % массы Земли.'),\n",
       "  Document(page_content='друг другу; друг (о, в) друге; один (у, за, на, из, из-под, для) другого; друг (у, за, перед) дружкой; друг (у, за, на, из, из-под, для) друга; друг (с, за, над, под, перед) другом; друг (о, в) друге; один (у, за, на, из, для) другого; один (в, за, на) один; один к одному (другому); один (в, за, на) один; друг (с, за, под, перед) дружкой; друг (у, из, из-под) дружки; друг на дружке; раз за (на) раз[ом]; от раза к разу; раз к разу; от случая к случаю; каждый (у, за, на, из, для) каждого; каждый за (над, под, перед) каждым. каждый в каждом; тот (у, в, за, на, из, из-под, для) [э]того; от того к [э]тому; в конце концов; от начала к началу; от первого ко второму; от противного к противному;')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke({\"query\": \"Что такое вода?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
